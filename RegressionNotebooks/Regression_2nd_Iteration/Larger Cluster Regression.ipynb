{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "#import sources.endomondolib as endo\n",
    "#import sources.pysparkconvenience as ps\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from pyspark.sql import DataFrameReader\n",
    "from pyspark.sql import SQLContext\n",
    "from IPython.display import display, HTML\n",
    "from pyspark.sql.functions import col, mean, min, max\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, GBTRegressor, RandomForestRegressor\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Disable warnings, set Matplotlib inline plotting and load Pandas package\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.mpl_style = 'default'\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.71 s\n"
     ]
    }
   ],
   "source": [
    "#sc = SQLContext()\n",
    "#create pyspark dataframe from csv\n",
    "def df_from_csv(csv_file):\n",
    "    text = sc.textFile(csv_file)\\\n",
    "       .map(lambda line: line.split(','))\n",
    "   #didn’t work with take(1). believe returns\n",
    "   #different object then first()\n",
    "    schema = text.first()\n",
    "    data = text.filter(lambda x: x != schema)\n",
    "    df = sqlContext.createDataFrame(data, schema)\n",
    "    return df\n",
    "\n",
    "pandas_df = pd.read_csv('f_clusters6.csv')\n",
    "df = sqlContext.createDataFrame(pandas_df)\n",
    "\n",
    "#here’s the new vectorizer function:\n",
    "\n",
    "def vectorizeData(data):\n",
    "        return data.rdd.map(lambda r: [r[0], r[1], r[2], r[3], Vectors.dense(r[4:-1]),float(r[-1])])\\\n",
    "            .toDF(['route cluster', 'performance cluster', 'userid', 'workoutid', 'features', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|     elapsed_time|\n",
      "+-------+-----------------+\n",
      "|  count|            24642|\n",
      "|   mean|4371.132132132132|\n",
      "| stddev|9182.794051238823|\n",
      "|    min|              501|\n",
      "|    max|          1108301|\n",
      "+-------+-----------------+\n",
      "\n",
      "time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "df.describe('elapsed_time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Unnamed: 0,LongType,true),StructField(route_prediction,LongType,true),StructField(perf_prediction,LongType,true),StructField(diff_altitude,DoubleType,true),StructField(geo_distance,DoubleType,true),StructField(userid,LongType,true),StructField(workoutid,LongType,true),StructField(heart_rate_avg,DoubleType,true),StructField(speed_avg,DoubleType,true),StructField(elapsed_time,LongType,true)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.32 ms\n"
     ]
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.5 ms\n"
     ]
    }
   ],
   "source": [
    "select_columns = ['route_prediction', 'perf_prediction','userid', 'workoutid', 'geo_distance', 'diff_altitude', \\\n",
    "                'speed_avg', 'heart_rate_avg', 'elapsed_time']\n",
    "df = df.select(select_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(route_prediction,LongType,true),StructField(perf_prediction,LongType,true),StructField(userid,LongType,true),StructField(workoutid,LongType,true),StructField(geo_distance,DoubleType,true),StructField(diff_altitude,DoubleType,true),StructField(speed_avg,DoubleType,true),StructField(heart_rate_avg,DoubleType,true),StructField(elapsed_time,LongType,true)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.37 ms\n"
     ]
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 238 ms\n"
     ]
    }
   ],
   "source": [
    "reg_df = vectorizeData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(route cluster,LongType,true),StructField(performance cluster,LongType,true),StructField(userid,LongType,true),StructField(workoutid,LongType,true),StructField(features,VectorUDT,true),StructField(label,DoubleType,true)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.33 ms\n"
     ]
    }
   ],
   "source": [
    "reg_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 663 ms\n"
     ]
    }
   ],
   "source": [
    "#distinct_clusters = reg_df.select('cluster').distinct().collect()\n",
    "#cluster_numbers = [int(distinct_clusters[i][0]) for i in range(len(distinct_clusters))]\n",
    "\n",
    "route_clusters = reg_df.select('route cluster').distinct().collect()\n",
    "perf_clusters = reg_df.select('performance cluster').distinct().collect()\n",
    "route_cluster_numbers = [int(route_clusters[i][0]) for i in range(len(route_clusters))]\n",
    "perf_cluster_numbers = [int(perf_clusters[i][0]) for i in range(len(perf_clusters))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24642"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "reg_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Route, Perf, Model): (0, 0, LinearRegression_4569ad2e01639820201e): 5708.4075864\n",
      "(Route, Perf, Model): (0, 1, LinearRegression_4569ad2e01639820201e): 866.367218946\n",
      "(Route, Perf, Model): (0, 3, LinearRegression_4569ad2e01639820201e): 1000.64071002\n",
      "(Route, Perf, Model): (0, 2, LinearRegression_4569ad2e01639820201e): 2333.12314457\n",
      "(Route, Perf, Model): (1, 0, LinearRegression_4569ad2e01639820201e): 9271.03566894\n",
      "(Route, Perf, Model): (1, 1, LinearRegression_4569ad2e01639820201e): 2989.91882036\n",
      "(Route, Perf, Model): (1, 3, LinearRegression_4569ad2e01639820201e): 1659.23441376\n",
      "(Route, Perf, Model): (1, 2, LinearRegression_4569ad2e01639820201e): 2392.20886312\n",
      "(Route, Perf, Model): (1, 4, LinearRegression_4569ad2e01639820201e): 1955.90771191\n",
      "(Route, Perf, Model): (2, 0, LinearRegression_4569ad2e01639820201e): 12476.201842\n",
      "(Route, Perf, Model): (2, 1, LinearRegression_4569ad2e01639820201e): 1286.44133045\n",
      "(Route, Perf, Model): (2, 3, LinearRegression_4569ad2e01639820201e): 874.70926226\n",
      "(Route, Perf, Model): (2, 2, LinearRegression_4569ad2e01639820201e): 1103.89577966\n",
      "(Route, Perf, Model): (2, 4, LinearRegression_4569ad2e01639820201e): 1037.02385265\n",
      "\n",
      "\n",
      "\n",
      "(Route, Perf, Model): (0, 0, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 4594.40727329\n",
      "(Route, Perf, Model): (0, 1, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 627.553511351\n",
      "(Route, Perf, Model): (0, 3, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 356.981877198\n",
      "(Route, Perf, Model): (0, 2, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 1824.88679548\n",
      "(Route, Perf, Model): (1, 0, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 5185.85870071\n",
      "(Route, Perf, Model): (1, 1, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 2470.91457142\n",
      "(Route, Perf, Model): (1, 3, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 943.719503875\n",
      "(Route, Perf, Model): (1, 2, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 2029.6687026\n",
      "(Route, Perf, Model): (1, 4, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 1192.30012999\n",
      "(Route, Perf, Model): (2, 0, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 4679.71512127\n",
      "(Route, Perf, Model): (2, 1, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 1186.64348598\n",
      "(Route, Perf, Model): (2, 3, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 625.489440474\n",
      "(Route, Perf, Model): (2, 2, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 825.568438316\n",
      "(Route, Perf, Model): (2, 4, DecisionTreeRegressor_4c7d9eefeb6aa66bd8ab): 367.228034077\n",
      "\n",
      "\n",
      "\n",
      "(Route, Perf, Model): (0, 0, GBTRegressor_47e3b9652ebe7327eb18): 3992.52524944\n",
      "(Route, Perf, Model): (0, 1, GBTRegressor_47e3b9652ebe7327eb18): 346.034994051\n",
      "(Route, Perf, Model): (0, 3, GBTRegressor_47e3b9652ebe7327eb18): 14.2913134909\n",
      "(Route, Perf, Model): (0, 2, GBTRegressor_47e3b9652ebe7327eb18): 698.41905314\n",
      "(Route, Perf, Model): (1, 0, GBTRegressor_47e3b9652ebe7327eb18): 3223.69957282\n",
      "(Route, Perf, Model): (1, 1, GBTRegressor_47e3b9652ebe7327eb18): 1231.49698606\n",
      "(Route, Perf, Model): (1, 3, GBTRegressor_47e3b9652ebe7327eb18): 391.840355762\n",
      "(Route, Perf, Model): (1, 2, GBTRegressor_47e3b9652ebe7327eb18): 1391.34891895\n",
      "(Route, Perf, Model): (1, 4, GBTRegressor_47e3b9652ebe7327eb18): 182.644176524\n",
      "(Route, Perf, Model): (2, 0, GBTRegressor_47e3b9652ebe7327eb18): 3278.76393091\n",
      "(Route, Perf, Model): (2, 1, GBTRegressor_47e3b9652ebe7327eb18): 724.042320131\n",
      "(Route, Perf, Model): (2, 3, GBTRegressor_47e3b9652ebe7327eb18): 319.435127147\n",
      "(Route, Perf, Model): (2, 2, GBTRegressor_47e3b9652ebe7327eb18): 669.067280499\n",
      "(Route, Perf, Model): (2, 4, GBTRegressor_47e3b9652ebe7327eb18): 38.8424072949\n",
      "\n",
      "\n",
      "\n",
      "(Route, Perf, Model): (0, 0, RandomForestRegressor_41f2a9abc4761888ba5c): 5433.40264715\n",
      "(Route, Perf, Model): (0, 1, RandomForestRegressor_41f2a9abc4761888ba5c): 681.056741435\n",
      "(Route, Perf, Model): (0, 3, RandomForestRegressor_41f2a9abc4761888ba5c): 749.529020308\n",
      "(Route, Perf, Model): (0, 2, RandomForestRegressor_41f2a9abc4761888ba5c): 1751.27584133\n",
      "(Route, Perf, Model): (1, 0, RandomForestRegressor_41f2a9abc4761888ba5c): 7279.89685254\n",
      "(Route, Perf, Model): (1, 1, RandomForestRegressor_41f2a9abc4761888ba5c): 2237.50183351\n",
      "(Route, Perf, Model): (1, 3, RandomForestRegressor_41f2a9abc4761888ba5c): 1097.82291059\n",
      "(Route, Perf, Model): (1, 2, RandomForestRegressor_41f2a9abc4761888ba5c): 2012.75059164\n",
      "(Route, Perf, Model): (1, 4, RandomForestRegressor_41f2a9abc4761888ba5c): 1500.0877155\n",
      "(Route, Perf, Model): (2, 0, RandomForestRegressor_41f2a9abc4761888ba5c): 6596.71696208\n",
      "(Route, Perf, Model): (2, 1, RandomForestRegressor_41f2a9abc4761888ba5c): 1139.76799068\n",
      "(Route, Perf, Model): (2, 3, RandomForestRegressor_41f2a9abc4761888ba5c): 711.538310787\n",
      "(Route, Perf, Model): (2, 2, RandomForestRegressor_41f2a9abc4761888ba5c): 919.08026984\n",
      "(Route, Perf, Model): (2, 4, RandomForestRegressor_41f2a9abc4761888ba5c): 735.778675005\n",
      "\n",
      "\n",
      "\n",
      "time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "#baseline with defaults\n",
    "model_list = [LinearRegression(featuresCol=\"features\", labelCol=\"label\"),\\\n",
    "              DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\"), \\\n",
    "              GBTRegressor(featuresCol=\"features\", labelCol=\"label\"),\\\n",
    "              RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")]\n",
    "\n",
    "\n",
    "\n",
    "for k in model_list:    \n",
    "    for n in perf_cluster_numbers:\n",
    "        for i in route_cluster_numbers:\n",
    "            #print(\"(Route, Perf, Model): \" + str((n,i,k)))\n",
    "            temp_df1 = reg_df[reg_df['route cluster']==i]\n",
    "            temp_df = temp_df1[reg_df['performance cluster']==n]\n",
    "            \n",
    "            if temp_df.count() == 0:\n",
    "                #print \"Cluster pair dropped\"\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                temp_lr = k\n",
    "                temp_lrModel = temp_lr.fit(temp_df['label','features'])\n",
    "                temp_df = temp_lrModel.transform(temp_df)\n",
    "\n",
    "                #paramGrid = ParamGridBuilder() \\\n",
    "                #.addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
    "                #.addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "                #.build()\n",
    "\n",
    "\n",
    "\n",
    "                evaluator = RegressionEvaluator(\n",
    "                    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "                #crossval = CrossValidator(estimator=pipeline,\n",
    "                #                          estimatorParamMaps=paramGrid,\n",
    "                #                          evaluator=BinaryClassificationEvaluator(),\n",
    "                #                          numFolds=3)  # use 3+ folds in practice#\n",
    "\n",
    "                # Run cross-validation, and choose the best set of parameters.\n",
    "                #cvModel = crossval.fit(training)\n",
    "\n",
    "                #pred = cvModel.transform(temp_df)\n",
    "\n",
    "                #Print the coefficients and intercept for linear regression\n",
    "                #print(\"Coefficients: \" + str(temp_lrModel.coefficients))\n",
    "                #print(\"Intercept: \" + str(temp_lrModel.intercept))\n",
    "\n",
    "\n",
    "\n",
    "                rmse = evaluator.evaluate(temp_df)\n",
    "                print(\"(Route, Perf, Model): \" + str((n,i,k)) +\": \" + str(rmse))\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 0\n",
      "(Route, Perf, Model): (0, 0, LinearRegression_41c082fb7598100478d7): 5708.40758648\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 1\n",
      "(Route, Perf, Model): (0, 1, LinearRegression_41c082fb7598100478d7): 866.367226622\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 3\n",
      "(Route, Perf, Model): (0, 3, LinearRegression_41c082fb7598100478d7): 1000.64071002\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 2\n",
      "(Route, Perf, Model): (0, 2, LinearRegression_41c082fb7598100478d7): 2333.12314615\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 0\n",
      "(Route, Perf, Model): (1, 0, LinearRegression_41c082fb7598100478d7): 9271.03566899\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 1\n",
      "(Route, Perf, Model): (1, 1, LinearRegression_41c082fb7598100478d7): 2989.9188208\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 3\n",
      "(Route, Perf, Model): (1, 3, LinearRegression_41c082fb7598100478d7): 1659.23441376\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 2\n",
      "(Route, Perf, Model): (1, 2, LinearRegression_41c082fb7598100478d7): 2392.20886312\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 4\n",
      "(Route, Perf, Model): (1, 4, LinearRegression_41c082fb7598100478d7): 1955.90771191\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 0\n",
      "(Route, Perf, Model): (2, 0, LinearRegression_41c082fb7598100478d7): 12476.201842\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 1\n",
      "(Route, Perf, Model): (2, 1, LinearRegression_41c082fb7598100478d7): 1286.44133045\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 3\n",
      "(Route, Perf, Model): (2, 3, LinearRegression_41c082fb7598100478d7): 874.709270543\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 2\n",
      "(Route, Perf, Model): (2, 2, LinearRegression_41c082fb7598100478d7): 1103.89577966\n",
      "For <class 'pyspark.ml.regression.LinearRegression'> and cluster 4\n",
      "(Route, Perf, Model): (2, 4, LinearRegression_41c082fb7598100478d7): 1037.02385265\n",
      "time: 23min 34s\n"
     ]
    }
   ],
   "source": [
    "#LinearRegression\n",
    "#masa edit w/ CV\n",
    "model_list = [LinearRegression(featuresCol=\"features\", labelCol=\"label\")]#,\\\n",
    "              #DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\"), \\\n",
    "              #GBTRegressor(featuresCol=\"features\", labelCol=\"label\"),\\\n",
    "              #RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")]\n",
    "\n",
    "k = model_list[0]\n",
    "\n",
    "for n in perf_cluster_numbers:\n",
    "    for i in route_cluster_numbers:\n",
    "        #print(\"(Route, Perf, Model): \" + str((n,i,k)))\n",
    "        temp_df1 = reg_df[reg_df['route cluster']==i]\n",
    "        temp_df = temp_df1[reg_df['performance cluster']==n]\n",
    "        temp_df_cv = temp_df\n",
    "\n",
    "        if temp_df.count() == 0:\n",
    "            #print \"Cluster pair dropped\"\n",
    "            pass\n",
    "            \n",
    "        else:\n",
    "            temp_lr = k\n",
    "            temp_lrModel = temp_lr.fit(temp_df['label','features'])\n",
    "            temp_df = temp_lrModel.transform(temp_df)\n",
    "\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(temp_lr.maxIter, [5, 10, 100]) \\\n",
    "            .addGrid(temp_lr.regParam, [0, 0.1, 0.01]) \\\n",
    "            .build()\n",
    "\n",
    "\n",
    "            evaluator = RegressionEvaluator(\n",
    "                labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "            crossval = CrossValidator(estimator=temp_lr,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=evaluator,\n",
    "                                      numFolds=10)  # use 3+ folds in practice\n",
    "\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            cvModel = crossval.fit(temp_df_cv)\n",
    "\n",
    "            pred = cvModel.transform(temp_df_cv)\n",
    "\n",
    "            print(\"For \" + str(type(temp_lr)) + \" and cluster \" + str(i))\n",
    "            #Print the coefficients and intercept for linear regression\n",
    "            #print(\"Coefficients: \" + str(temp_lrModel.coefficients))\n",
    "            #print(\"Intercept: \" + str(temp_lrModel.intercept))\n",
    "\n",
    "\n",
    "\n",
    "            rmse = evaluator.evaluate(pred)\n",
    "            print(\"(Route, Perf, Model): \" + str((n,i,k)) +\": \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 0\n",
      "(Route, Perf, Model): (0, 0, DecisionTreeRegressor_4f0497d7220292fec819): 5582.01486875\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 1\n",
      "(Route, Perf, Model): (0, 1, DecisionTreeRegressor_4f0497d7220292fec819): 627.553511351\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 3\n",
      "(Route, Perf, Model): (0, 3, DecisionTreeRegressor_4f0497d7220292fec819): 945.287293639\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 2\n",
      "(Route, Perf, Model): (0, 2, DecisionTreeRegressor_4f0497d7220292fec819): 2289.71520794\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 0\n",
      "(Route, Perf, Model): (1, 0, DecisionTreeRegressor_4f0497d7220292fec819): 8994.42132061\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 1\n",
      "(Route, Perf, Model): (1, 1, DecisionTreeRegressor_4f0497d7220292fec819): 2979.04526835\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 3\n",
      "(Route, Perf, Model): (1, 3, DecisionTreeRegressor_4f0497d7220292fec819): 943.719503875\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 2\n",
      "(Route, Perf, Model): (1, 2, DecisionTreeRegressor_4f0497d7220292fec819): 2029.6687026\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 4\n",
      "(Route, Perf, Model): (1, 4, DecisionTreeRegressor_4f0497d7220292fec819): 1192.30012999\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 0\n",
      "(Route, Perf, Model): (2, 0, DecisionTreeRegressor_4f0497d7220292fec819): 11929.6020929\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 1\n",
      "(Route, Perf, Model): (2, 1, DecisionTreeRegressor_4f0497d7220292fec819): 1289.9114674\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 3\n",
      "(Route, Perf, Model): (2, 3, DecisionTreeRegressor_4f0497d7220292fec819): 912.529713043\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 2\n",
      "(Route, Perf, Model): (2, 2, DecisionTreeRegressor_4f0497d7220292fec819): 825.568438316\n",
      "For <class 'pyspark.ml.regression.DecisionTreeRegressor'> and cluster 4\n",
      "(Route, Perf, Model): (2, 4, DecisionTreeRegressor_4f0497d7220292fec819): 367.228034077\n",
      "time: 15min 47s\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeRegressor\n",
    "#masa edit w/ CV\n",
    "#[LinearRegression(featuresCol=\"features\", labelCol=\"label\"),\\\n",
    "model_list = [DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\",maxMemoryInMB=2056)]#, \\\n",
    "              #GBTRegressor(featuresCol=\"features\", labelCol=\"label\"),\\\n",
    "              #RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")]\n",
    "\n",
    "\n",
    "k = model_list[0]\n",
    "\n",
    "for n in perf_cluster_numbers:\n",
    "    for i in route_cluster_numbers:\n",
    "        #print(\"(Route, Perf, Model): \" + str((n,i,k)))\n",
    "        temp_df1 = reg_df[reg_df['route cluster']==i]\n",
    "        temp_df = temp_df1[reg_df['performance cluster']==n]\n",
    "        temp_df_cv = temp_df\n",
    "\n",
    "        if temp_df.count() == 0:\n",
    "            #print \"Cluster pair dropped\"\n",
    "            pass\n",
    "            \n",
    "        else:\n",
    "            temp_lr = k\n",
    "            temp_lrModel = temp_lr.fit(temp_df['label','features'])\n",
    "            temp_df = temp_lrModel.transform(temp_df)\n",
    "        \n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(temp_lr.maxDepth, [3, 5]) \\\n",
    "            .addGrid(temp_lr.minInfoGain, [0, 0.1, 1]) \\\n",
    "            .build()\n",
    "\n",
    "\n",
    "            evaluator = RegressionEvaluator(\n",
    "                labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "            crossval = CrossValidator(estimator=temp_lr,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=evaluator,\n",
    "                                      numFolds=10)  # use 3+ folds in practice\n",
    "\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            cvModel = crossval.fit(temp_df_cv)\n",
    "\n",
    "            pred = cvModel.transform(temp_df_cv)\n",
    "\n",
    "\n",
    "            #print(\"For \" + str(type(temp_lr)) + \" and cluster \" + str(i))\n",
    "            #print(cvModel.explainParams())\n",
    "\n",
    "            #Print the coefficients and intercept for linear regression\n",
    "            #print(\"Coefficients: \" + str(temp_lrModel.coefficients))\n",
    "            #print(\"Intercept: \" + str(temp_lrModel.intercept))\n",
    "\n",
    "\n",
    "\n",
    "            rmse = evaluator.evaluate(pred)\n",
    "            print(\"(Route, Perf, Model): \" + str((n,i,k)) +\": \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Route, Perf, Model): (0,0,GBTRegressor_47c8b1ce325ef2a47503) dropped\n",
      "time: 1.08 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"(Route, Perf, Model): (%d,%d,%s) dropped\" % (n,i,k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a00435ea7974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtemp_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mtemp_lrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_lrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/spark-2.1.0-bin-hadoop2.7/python/pyspark/ml/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/opt/spark/spark-2.1.0-bin-hadoop2.7/python/pyspark/ml/wrapper.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/spark-2.1.0-bin-hadoop2.7/python/pyspark/ml/wrapper.pyc\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \"\"\"\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.35 s\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosted Trees\n",
    "#masa edit w/ CV\n",
    "#[LinearRegression(featuresCol=\"features\", labelCol=\"label\"),\\\n",
    "#DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\",maxMemoryInMB=1028)]#, \\             \n",
    "model_list = [GBTRegressor(featuresCol=\"features\", labelCol=\"label\", maxMemoryInMB=4128,lossType=\"absolute\")]#,\\\n",
    "              #RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")]\n",
    "k = model_list[0]\n",
    "\n",
    "f = open('GBT_Larger_Cluster_Regression_Output.txt', 'w')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for n in perf_cluster_numbers:\n",
    "    for i in route_cluster_numbers:\n",
    "        #print(\"(Route, Perf, Model): \" + str((n,i,k)))\n",
    "        temp_df1 = reg_df[reg_df['route cluster']==i]\n",
    "        temp_df = temp_df1[reg_df['performance cluster']==n]\n",
    "        temp_df_cv = temp_df\n",
    "\n",
    "        if temp_df.count() == 0:\n",
    "            #print \"Cluster pair dropped\"\n",
    "            print(\"(Route, Perf, Model): (%d,%d,%s) dropped\" % (n,i,k))\n",
    "            f.write(\"(Route, Perf, Model): (%d,%d,%s) dropped\" % (n,i,k))\n",
    "            pass\n",
    "            \n",
    "        else:\n",
    "            temp_lr = k\n",
    "            temp_lrModel = temp_lr.fit(temp_df['label','features'])\n",
    "            temp_df = temp_lrModel.transform(temp_df)\n",
    "        \n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(temp_lr.maxDepth, [3, 5]) \\\n",
    "            .addGrid(temp_lr.maxIter, [10,20,40]) \\\n",
    "            .build()\n",
    "\n",
    "\n",
    "            evaluator = RegressionEvaluator(\n",
    "                labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "            crossval = CrossValidator(estimator=temp_lr,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=evaluator,\n",
    "                                      numFolds=10)  # use 3+ folds in practice\n",
    "\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            cvModel = crossval.fit(temp_df_cv)\n",
    "\n",
    "            pred = cvModel.transform(temp_df_cv)\n",
    "\n",
    "\n",
    "            #print(\"For \" + str(type(temp_lr)) + \" and cluster \" + str(i))\n",
    "            #print(cvModel.explainParams())\n",
    "\n",
    "            #Print the coefficients and intercept for linear regression\n",
    "            #print(\"Coefficients: \" + str(temp_lrModel.coefficients))\n",
    "            #print(\"Intercept: \" + str(temp_lrModel.intercept))\n",
    "\n",
    "\n",
    "\n",
    "            rmse = evaluator.evaluate(pred)\n",
    "            print(\"(Route, Perf, Model): \" + str((n,i,k)) +\": \" + str(rmse))\n",
    "            f.write(\"(Route, Perf, Model): \" + str((n,i,k)) +\": \" + str(rmse) +\"\\n\")\n",
    "            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Route, Perf, Model): (0, 0, RandomForestRegressor_446490fbdefa6279d5c7): 5568.40799134\n",
      "(Route, Perf, Model): (0, 1, RandomForestRegressor_446490fbdefa6279d5c7): 681.056741435\n",
      "(Route, Perf, Model): (0, 3, RandomForestRegressor_446490fbdefa6279d5c7): 658.119447519\n",
      "(Route, Perf, Model): (0, 2, RandomForestRegressor_446490fbdefa6279d5c7): 1751.27584133\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unsupported format character 'w' (0x77) at index 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-dbf488b80576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(Route, Perf, Model): (%d,%d,%w) dropped\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(Route, Perf, Model): (%d,%d,%w) dropped\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported format character 'w' (0x77) at index 30"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regressor\n",
    "#masa edit w/ CV\n",
    "#[LinearRegression(featuresCol=\"features\", labelCol=\"label\"),\\\n",
    "#DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\",maxMemoryInMB=1028)], \\             \n",
    "#GBTRegressor(featuresCol=\"features\", labelCol=\"label\", maxMemoryInMB=2056)],\\\n",
    "model_list = [RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\", maxMemoryInMB = 4122)]\n",
    "\n",
    "\n",
    "k = model_list[0]\n",
    "\n",
    "for n in perf_cluster_numbers:\n",
    "    for i in route_cluster_numbers:\n",
    "        temp_df = reg_df[(reg_df['route cluster'] == i) & (reg_df['performance cluster'] == n)]\n",
    "        #temp_df1 = reg_df[reg_df['route cluster']==i]\n",
    "        #temp_df = temp_df1[reg_df['performance cluster']==n]\n",
    "        temp_df_cv = temp_df\n",
    "\n",
    "        if temp_df.count() == 0:\n",
    "            print(\"(Route, Perf, Model): (%d,%d,%s) dropped\" % (n,i,k))\n",
    "            f.write(\"(Route, Perf, Model): (%d,%d,%s) dropped\\n\" % (n,i,k))\n",
    "            pass\n",
    "            \n",
    "        else:\n",
    "            temp_lr = k\n",
    "            temp_lrModel = temp_lr.fit(temp_df['label','features'])\n",
    "            temp_df = temp_lrModel.transform(temp_df)\n",
    "        \n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(temp_lr.maxDepth, [3, 5]) \\\n",
    "            .addGrid(temp_lr.numTrees, [10,20,40]) \\\n",
    "            .build()\n",
    "\n",
    "\n",
    "            evaluator = RegressionEvaluator(\n",
    "                labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "            crossval = CrossValidator(estimator=temp_lr,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=evaluator,\n",
    "                                      numFolds=10)  # use 3+ folds in practice\n",
    "\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            cvModel = crossval.fit(temp_df_cv)\n",
    "\n",
    "            pred = cvModel.transform(temp_df_cv)\n",
    "\n",
    "\n",
    "            #print(\"For \" + str(type(temp_lr)) + \" and cluster \" + str(i))\n",
    "            #print(cvModel.explainParams())\n",
    "\n",
    "            #Print the coefficients and intercept for linear regression\n",
    "            #print(\"Coefficients: \" + str(temp_lrModel.coefficients))\n",
    "            #print(\"Intercept: \" + str(temp_lrModel.intercept))\n",
    "\n",
    "\n",
    "\n",
    "            rmse = evaluator.evaluate(pred)\n",
    "            print(\"(Route, Perf, Model): \" + str((n,i,k)) +\": \" + str(rmse))\n",
    "            f.write(\"(Route, Perf, Model): \" + str((n,i,k)) +\": \" + str(rmse) +\"\\n\")\n",
    "            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
